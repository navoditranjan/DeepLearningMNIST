{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist) ##It is a special tensorflow dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f338c774550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCD+QFOEHkiL8QFKEH0iK8ANJEX4gqf8HAIELZI9qhowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f338c810208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample,cmap='Greys')   ##rEALISTIC IMPLEMENTATIONS OF WHAT DATAS ACTUALLY LOOKS LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    \"x:placeHolder for data input\"\n",
    "    \"weights: Dict of Weights\"\n",
    "    \"biases:dict of bias values\"\n",
    "    \n",
    "    #First hidden layer with RELU activation\n",
    "    # X*W + B\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    #RELU(X*W + B) -> f(x) = max(0,x)\n",
    "    layer1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #Second Hidden Layer\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    \n",
    "    #Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Weight Dictionaries\n",
    "weights = {\n",
    "    \n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tf.Variable 'Variable_3:0' shape=(784, 256) dtype=float32_ref>,\n",
       " 'h2': <tf.Variable 'Variable_4:0' shape=(256, 256) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_5:0' shape=(256, 10) dtype=float32_ref>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Biases Dictionaries\n",
    "biases = {\n",
    "    \n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float',[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y)) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) ##Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xsamp,ysamp = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f338bc42a90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f338bd426d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xsamp.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/navodit/miniconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost54.2942\n",
      "Epoch: 2 cost34.9580\n",
      "Epoch: 3 cost24.9800\n",
      "Epoch: 4 cost18.7495\n",
      "Epoch: 5 cost14.0997\n",
      "Epoch: 6 cost10.7534\n",
      "Epoch: 7 cost8.4540\n",
      "Epoch: 8 cost6.6718\n",
      "Epoch: 9 cost5.3468\n",
      "Epoch: 10 cost4.2290\n",
      "Epoch: 11 cost3.5053\n",
      "Epoch: 12 cost2.8311\n",
      "Epoch: 13 cost2.2249\n",
      "Epoch: 14 cost2.0703\n",
      "Epoch: 15 cost1.6197\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "#15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        _,c = sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "    \n",
    "    print(\"Epoch: {} cost{:.4f}\".format(epoch+1,avg_cost))\n",
    "    \n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)  ##Accuracy is still a tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels.shape  ##y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape   ##x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94859999"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
